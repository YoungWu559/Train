<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="viewport" content="width=device-width, initial-scale=1">
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-34711826-1', 'auto');
  ga('send', 'pageview');
</script>
<script src="YJS.js?0.3713922673637605" type="model" defer></script>
<script src="CS540.js?0.7662253439422075" type="model" defer></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/seedrandom/3.0.5/seedrandom.min.js"></script> 
<script src="https://cdnjs.cloudflare.com/ajax/libs/numeric/1.2.6/numeric.min.js"></script>
<script src="https://unpkg.com/mathjs@6.1.0/dist/math.min.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<title>Young Wu's Homepage</title>
<link rel="shortcut icon" href="favicon.ico">
<link rel="stylesheet" href="style540.css" type="text/css">
</head>
<body>
<div id="masthead">
<h1 id="siteName">CS540 Summer 2020 Epic Section</h1>
</div> 
<div id="content">
<a href="CS540W2S20E.htm">Next: W2</a> <br>
<br>
<h2>Summary</h2>
&bull; Examples and quizzes: <a href="CS540E1S20E.htm">E1</a> <br>
&bull; Math homework: <a href="CS540M1S20E.htm">M1</a> and <a href="CS540M2S20E.htm">M2</a> <br>
&bull; Programming homework: part 1 of <a href="CS540P1S20E.htm">P1</a> <br>
&bull; Monday lecture: 5:30 to 8:30, <a href="https://us.bbcollab.com/guest/a65d4cb33bb7400d8951604d6e252d41" target="_blank">Guest Link</a> <br>
&bull; Tuesday programming office hours: 5:00 to 6:00, <a href="https://us.bbcollab.com/guest/cb7aa89f97b7423595ae1e4aa638234a" target="_blank">Java Guest Link</a>, <a href="https://us.bbcollab.com/guest/cb7aa89f97b7423595ae1e4aa638234a" target="_blank">Python Guest Link</a> (same for the first two weeks) <br>
&bull; Wednesday math homework office hours: 5:00 to 6:00, <a href="https://us.bbcollab.com/guest/cb7aa89f97b7423595ae1e4aa638234a" target="_blank">Guest Link</a> <br>
&bull; Thursday math homework office hours: 5:00 to 6:00 (not the first two weeks) <br>
&bull; Friday office hours for other things: 5:00 to 6:00, <a href="https://us.bbcollab.com/guest/cb7aa89f97b7423595ae1e4aa638234a" target="_blank">Guest Link</a> <br>
<br>
<h2>Lectures</h2>
&bull; Slides <br>
Lecture 1: <a href="CS540/CS540_Lecture_1_P.pdf">Slides</a> <br>
Lecture 2: <a href="CS540/CS540_Lecture_2_P.pdf">Slides</a> <br>
<br>
&bull; Videos <br>
Lecture 1 Part 1 (Admin): <a href="https://youtu.be/o1u4C7F2tXg" target="_blank">Link</a> <br>
Lecture 1 Part 2 (Supervised learning): <a href="https://youtu.be/RvMdszmMoIM" target="_blank">Link</a> <br>
Lecture 1 Part 3 (Perceptron learning): <a href="https://youtu.be/LBLObGx_JA0" target="_blank">Link</a> <br>
Lecture 2 Part 1 (Loss functions): <a href="https://youtu.be/qJD96GHW1zs" target="_blank">Link</a> <br>
Lecture 2 Part 2 (Logistic regression): <a href="https://youtu.be/SOIsZu7rFqI" target="_blank">Link</a> <br>
Lecture 2 Part 3 (Convexity): <a href="https://youtu.be/xFHRfKhXof0" target="_blank">Link</a> <br>
<br>
&bull; Notes <br>
I recorded a video going through the M1 questions while review some of the math concepts: <a href="https://youtu.be/YTXtvFglkpU" target="_blank">Link</a>, you do not have to watch this and lecture 2 part 3 if you have taken Calculus 2 and (Linear) Algebra 1. <br>
Last year's perceptron update rule explanation perhaps is clearer: <a href="https://youtu.be/yDBuTq-Dcl8" target="_blank">Link</a> <br>
I forgot to mention in the video that we are starting with machine learning (the more difficult half) and we will cover search and games (the easier half) after the midterm. The order of the topics is reversed from the course in fall and winter semesters, but by the end of the summer, we will have covered the same materials. <br>
For Robert Downey Jr. fans, his 2 min intro to AI is great: <a href="https://www.youtube.com/watch?v=UwsrzCVZAb8" target="_blank">Link</a>, although it's not what we will do in this course <br>
<br>
<h2>Other Materials</h2>
&bull; Relevant websites <br>
Which face is real? <a href="http://www.whichfaceisreal.com/" target="_blank">Link</a> <br>
Guess two-thirds of the average? <a href="https://www.nytimes.com/interactive/2015/08/13/upshot/are-you-smarter-than-other-new-york-times-readers.html" target="_blank">Link</a> <br>
Gradient Descent. <a href="https://www.benfrederickson.com/numerical-optimization/" target="_blank">Link</a> <br>
Eigenvalue in Endgame. <a href="https://www.newsweek.com/avengers-endgame-time-travel-quantum-mechanics-explained-scientist-1405522" target="_blank">Link</a> <br>
Plot 3D functions: <a href="https://www.geogebra.org/3d?lang=en" target="_blank">Link</a> <br>
<br>
<img src="https://cdn-images-1.medium.com/max/1200/1*x7P7gqjo8k2_bj2rTQWAfg.jpeg" alt="Stat" style="width:300px; height:300px"> <br>
<br>
&bull; YouTube videos from 2019 <br>
Why does the (batch) perceptron algorithm work? <a href="https://youtu.be/yDBuTq-Dcl8" target="_blank">Link</a> <br>
Why cannot use linear regression for binary classification? <a href="https://youtu.be/XVJebT836Lk" target="_blank">Link</a> <br>
Why does gradient descent work? <a href="https://youtu.be/DEiJs_fWCM8" target="_blank">Link</a> <br>
How to derive logistic regression gradient descent step formula? <a href="https://youtu.be/6appiGd8BoE" target="_blank">Link</a> <br>
Example (Quiz): Perceptron update formula <a href="https://youtu.be/bdiyBRxyfgk" target="_blank">Link</a> <br>
Example (Quiz): Gradient descent for logistic activation with squared error <a href="https://youtu.be/k3wzAOoDOBY" target="_blank">Link</a> <br>
Example (Quiz): Computation of Hessian of quadratic form <a href="https://youtu.be/pHz7L-jZXgw" target="_blank">Link</a> <br>
Example (Quiz): Computation of eigenvalues <a href="https://youtu.be/Dr-WC0BUQd4" target="_blank">Link</a> <br>
Example (Homework): Gradient descent for linear regression <a href="https://youtu.be/Rhxf-jpRE5M" target="_blank">Link</a> <br>
<br>
&bull; Math and Statistics Review <br>
Checklist: <a href="http://pages.cs.wisc.edu/~jerryzhu/cs540.html" target="_blank">Link</a>, "math crib sheet" under "10/11" <br>
Multivariate Calculus: <a href="https://www.whitman.edu/mathematics/calculus_late_online/" target="_blank">Textbook</a>, Chapter 16 and/or (Economics) <a href="https://mjo.osborne.economics.utoronto.ca/index.php/tutorial/index/1/toc" target="_blank">Tutorials</a>, Chapters 2 and 3. <br>
Linear Algebra: <a href="http://linear.ups.edu/html/fcla.html" target="_blank">Textbook</a>, Chapters on Determinant and Eigenvalue. <br>
Probability and Statistics: <a href="https://www.probabilitycourse.com/" target="_blank">Textbook</a>, Chapters 3, 4, 5. <br>
<br>
<br>
<br>
<br>
<br>
<font color="grey" size = 2> Last Updated: June 16, 2020 at 12:25 AM</font><br>
<br>
</div>
<div id="primarynavarea">
<ul id="primarynav">
<li><a href="CS540S20E.htm"><span class="secondcolor"><strong>Home</strong></span></a></li>
<ul id="primarynavsub">
<li><a href="CS540W1S20E.htm">Week 1 </a></li>
<li><a href="CS540W2S20E.htm">Week 2 </a></li>
<li><a href="CS540W3S20E.htm">Week 3 </a></li>
<li><a href="CS540W4S20E.htm">Week 4 </a></li>
<li><a href="CS540W5S20E.htm">Week 5 </a></li>
<li><a href="CS540W6S20E.htm">Week 6 </a></li>
<li><a href="CS540W7S20E.htm">Week 7 </a></li>
<li><a href="CS540W9S20E.htm">Week 9 </a></li>
<li><a href="CS540W10S20E.htm">Week 10 </a></li>
<li><a href="CS540W11S20E.htm">Week 11 </a></li>
<li><a href="CS540W12S20E.htm">Week 12 </a></li>
<li><a href="CS540W13S20E.htm">Week 13 </a></li>
</ul>
<li><a href="CS540W8S20E.htm">Midterm </a></li>
<li><a href="CS540W14S20E.htm">Final </a></li>
</ul>
</div>
<div id="siteInfo">&nbsp;<img style="width: 191px; height: 65px;" alt="" src="image003.png">
</div>
</body>
</html>
